Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/Users/similoluwaokunowo/Desktop/Codes/gcp-tutorial-aims-gemma-finetune/scripts/run_evaluate.py", line 20, in <module>
    main()
  File "/Users/similoluwaokunowo/Desktop/Codes/gcp-tutorial-aims-gemma-finetune/scripts/run_evaluate.py", line 12, in main
    evaluate(
  File "/Users/similoluwaokunowo/Desktop/Codes/gcp-tutorial-aims-gemma-finetune/src/evaluate.py", line 73, in evaluate
    outputs = model(
              ^^^^^^
  File "/Users/similoluwaokunowo/Desktop/Codes/gcp-tutorial-aims-gemma-finetune/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1776, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/similoluwaokunowo/Desktop/Codes/gcp-tutorial-aims-gemma-finetune/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1787, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/similoluwaokunowo/Desktop/Codes/gcp-tutorial-aims-gemma-finetune/.venv/lib/python3.12/site-packages/transformers/utils/generic.py", line 841, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/similoluwaokunowo/Desktop/Codes/gcp-tutorial-aims-gemma-finetune/.venv/lib/python3.12/site-packages/transformers/models/gemma3/modeling_gemma3.py", line 653, in forward
    outputs: BaseModelOutputWithPast = self.model(
                                       ^^^^^^^^^^^
  File "/Users/similoluwaokunowo/Desktop/Codes/gcp-tutorial-aims-gemma-finetune/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1776, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/similoluwaokunowo/Desktop/Codes/gcp-tutorial-aims-gemma-finetune/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1787, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/similoluwaokunowo/Desktop/Codes/gcp-tutorial-aims-gemma-finetune/.venv/lib/python3.12/site-packages/transformers/utils/generic.py", line 915, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/similoluwaokunowo/Desktop/Codes/gcp-tutorial-aims-gemma-finetune/.venv/lib/python3.12/site-packages/transformers/utils/output_capturing.py", line 253, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/similoluwaokunowo/Desktop/Codes/gcp-tutorial-aims-gemma-finetune/.venv/lib/python3.12/site-packages/transformers/models/gemma3/modeling_gemma3.py", line 542, in forward
    inputs_embeds = self.embed_tokens(input_ids)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/similoluwaokunowo/Desktop/Codes/gcp-tutorial-aims-gemma-finetune/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1776, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/similoluwaokunowo/Desktop/Codes/gcp-tutorial-aims-gemma-finetune/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1787, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/similoluwaokunowo/Desktop/Codes/gcp-tutorial-aims-gemma-finetune/.venv/lib/python3.12/site-packages/transformers/models/gemma3/modeling_gemma3.py", line 113, in forward
    return super().forward(input_ids) * self.embed_scale.to(self.weight.dtype)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/similoluwaokunowo/Desktop/Codes/gcp-tutorial-aims-gemma-finetune/.venv/lib/python3.12/site-packages/torch/nn/modules/sparse.py", line 191, in forward
    return F.embedding(
           ^^^^^^^^^^^^
  File "/Users/similoluwaokunowo/Desktop/Codes/gcp-tutorial-aims-gemma-finetune/.venv/lib/python3.12/site-packages/torch/nn/functional.py", line 2567, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: embedding(): argument 'indices' (position 2) must be Tensor, not BatchEncoding
